{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4ef61b-3397-4f64-9648-7124ecf8299a",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7f6ba-59ca-469d-bfcc-2e81a385191c",
   "metadata": {},
   "source": [
    "## Intuición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d781e-80f9-415c-8cd1-bccef30c493c",
   "metadata": {},
   "source": [
    "Supongamos que estamos leyendo la descripción de un ordenador. Hay palabras que no nos importan mucho y lo mas probable que con el paso del tiempo las vamos a olvidar.\n",
    "\n",
    "Si un día alguien nos pregunta, seguro recordaremos los puntos principales.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df755027-cd2d-4fcd-ad42-7248ccbecfd6",
   "metadata": {},
   "source": [
    "<img src=\"images/notebook_rnn.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6336db3-bd22-4dfa-99c2-c76bf9bed8a3",
   "metadata": {},
   "source": [
    "### Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1711d11-bd91-4eb9-a59a-0ab50554e4db",
   "metadata": {},
   "source": [
    "La **notebook Apple MacBook Air** A1466 es una solución tanto **para trabajar y estudiar** como para **entretenerte**. Al ser **portátil**, el escritorio dejará de ser tu único espacio de uso para abrirte las puertas a otros ambientes ya sea en tu casa o en la oficina.\n",
    "\n",
    "**Pantalla con gran impacto visual**.\n",
    "Su **pantalla LED de 13.3\"** y 1440x900 px de resolución te brindará **colores** más **vivos y definidos***. Tus películas y series preferidas cobrarán vida, ya que ganarán **calidad y definición** en cada detalle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294505e-2a59-436f-890a-2c9e0e09daac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ¿Qué hace que aparezcan este tipo de redes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84115c-272f-45a6-8649-ad037a3ac84a",
   "metadata": {},
   "source": [
    "Primera RNN, 1980: https://www.nature.com/articles/323533a0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af13f70-e150-4ead-9672-986001d5b934",
   "metadata": {},
   "source": [
    "* Las redes neuronales tradicionales (vanillas) solo aceptan un vector de entrada de tamaño fijo y devuelve un vector de salida de tamaño fijo.\n",
    "* Las redes neuronales permiten operar sobre secuencias de vectores: secuencias en la entrada, en la salida o, en el caso más general, en ambas.\n",
    "\n",
    "\n",
    "* En las redes neuronales feed-forward, la información solo se mueve hacia adelante (de la capa de entrada hacia las capas ocultas, hasta la capa de salida).\n",
    "* Las nn feed-forward no tienen memoria de la entrada que recibe -> son malas para predecir lo que \"viene\", ya que solo considera la entrada actual.\n",
    "\n",
    "* En un RNN, la información recorre un ciclo. Cuando toma una decisión, considera la entrada actual y también lo que ha aprendido de las entradas que recibió anteriormente.\n",
    "\n",
    "* Un RNN básica tiene memoria a corto plazo. En combinación con un LSTM, también tienen una memoria a largo plazo (ya lo veremos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06cb49d-54ba-4bb8-a5de-5805be66ed65",
   "metadata": {},
   "source": [
    "<img src=\"images/ffvsrnn.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb880d3-1574-4c00-af0a-06ad7fad47ee",
   "metadata": {},
   "source": [
    "#### Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36caaf2-a09f-4fa8-b382-91b1be69386e",
   "metadata": {},
   "source": [
    "* Las entradas se convierten en un vector numérico.\n",
    "* Luego la RNN procesa la secuencia de vectores uno a uno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626ad26-15f5-45f5-9f25-806c5d4a9dfa",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_procesamiento.gif\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f3fc1-f8ad-446b-b880-1104e8a12b2e",
   "metadata": {},
   "source": [
    "Suponer que una red feed-forward le damos como entrada la palabra **\"NEURONAL\"**, la cual tiene que procesar caracter a caracter. Cuando llegue a la **U** ya se \"olvidó\" de \"N\" \"E\", por lo que es muy difícil que puede predecr que caracter viene después."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707138a5-ade0-4ca9-829b-009066480809",
   "metadata": {},
   "source": [
    "* Una red recurrente sería adecuada para recordar dichos caracteres debido a la memoria interna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa05331-79e3-40aa-ad77-e1711ec8259c",
   "metadata": {},
   "source": [
    "#### Diferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e49dcc-4cdf-4ce9-8d8d-f95064e372e4",
   "metadata": {},
   "source": [
    "* A diferencia de una red tradicional, un RNN tiene mas de 1 entrada (el presente y el pasado reciente).\n",
    "\n",
    "* Una red neuronal feed-forward asigna, como todos los demás algoritmos de aprendizaje profundo, una matriz de peso a sus entradas y luego produce la salida. \n",
    "\n",
    "* Las RNN aplican ponderaciones a la entrada actual y también a la anterior. Además, una red neuronal recurrente también ajustará los pesos tanto para el descenso de gradiente como para la propagación inversa a través del tiempo (BPTT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1baeec-438c-40e7-946d-dba34190ef9f",
   "metadata": {},
   "source": [
    "#### BPTT: Backpropagation through time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dcb402-2ccb-4bf5-9aae-cdc24660a431",
   "metadata": {},
   "source": [
    "BPTT solo es la forma de hacer retropropagación hacia atrás en RNNs.\n",
    "\n",
    "A una RNN se la puede ver como una secuencia de redes neuronales que entrena una tras otra con backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac82165-3af9-4c8c-8b14-bfac396dfa09",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_rolled.png\" alt=\"drawing\" width=\"100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ece785-ec71-4330-b401-f2a5fb72c25b",
   "metadata": {},
   "source": [
    "La siguiente imagen muestra por qué se puede ver como una secuencia de redes neuronales. \n",
    "\n",
    "El **error** de un paso de tiempo determinado depende del paso de tiempo anterior. El BPTT aumenta su costo computacional en funcion de los pasos de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af1247-5245-4359-a448-40976f6afaf9",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_unrolled.png\" alt=\"drawing\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364e20c-1339-471e-9b49-b5c2a753a0f7",
   "metadata": {},
   "source": [
    "Durante el **procesamiento**, \n",
    "\n",
    "1. Pasa el **estado oculto** anterior al siguiente paso de la secuencia. El estado oculto actúa como la memoria de las redes neuronales. Contiene información sobre datos anteriores que la red ha visto antes.\n",
    "\n",
    "2. ¿Cómo se calcula estado oculto?\n",
    "\n",
    "Primero, la entrada y el estado oculto anterior se combinan en un vector. Ese vector ahora tiene información sobre la entrada actual y las entradas anteriores. El vector pasa por la activación tanh (valores entre -1 y 1) y la salida es el nuevo estado oculto (la **memoria de la red**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305e485-aa40-4919-8459-32144dbc2472",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_animado.gif\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd025f38-4580-4e91-beb5-32905b873d4e",
   "metadata": {},
   "source": [
    "#### Problemas de las RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af284e19-9701-4e4d-9c4a-c50c0150660c",
   "metadata": {},
   "source": [
    "* **Exploding gradients**: básicamente se acumulan grandes gradientes de error y la actualización de los pesos son tan grandes que se inestabiliza el entrenamiento, produce desbordamiento de memoria, etc. ¿Cómo saber si pasa? ¿Se resuelve fácil? -> Regularizacion, aplastar el gradiente, rediseñar la arquitectura de red, otros..\n",
    "* **Vanishig gradients**: los valores de un gradiente son tan pequeños que el modelo tarda mucho en aprender o nunca converje. Sucede en las redes de gran tamaño.. Usar funciones de activación como ReLU que no genera una derivada demasiado pequeña puede ayudar. Hay otras alternativas como Batch normalization: normalizacion de entradas de las capas: centrado y escalado.\n",
    "* La **brecha entre la información relevante y el punto donde se necesita** se vuelva muy **grande**. (La teoría dice que las RNN debería resolverlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17c4ac-2e11-4a5c-9989-2d6b72634630",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_long_dependencies.png\" alt=\"drawing\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114de16-ced8-45d4-b222-05239387a0bb",
   "metadata": {},
   "source": [
    "## LSTM - Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec3ff8-9d05-4522-be95-9f92298fbdb3",
   "metadata": {},
   "source": [
    "LSTM, 1997: https://direct.mit.edu/neco/article-abstract/9/8/1735/6109/Long-Short-Term-Memory?redirectedFrom=fulltext\n",
    "\n",
    "Las redes de memoria a corto y largo plazo, generalmente llamadas simplemente \"LSTM\", son un tipo especial de RNN, capaz de aprender las dependencias a largo plazo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3058-50e8-402c-a227-b42e02dfc007",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_simple.png\" alt=\"drawing\" width=\"450\"/>\n",
    "El módulo de repetición en un RNN tradicional contiene una sola capa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e02190-34a4-416a-b0dd-7e3f0a0efb4c",
   "metadata": {},
   "source": [
    "<img src=\"images/lstm.png\" alt=\"drawing\" width=\"450\"/>\n",
    "El módulo de repetición en un LSTM contiene cuatro capas que interactúan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1eb4c7-bab8-469d-87a2-1535f3e18489",
   "metadata": {},
   "source": [
    "#### ¿Cómo incorporar información a largo plazo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f66044-fe34-4046-9962-e66bc783aed3",
   "metadata": {},
   "source": [
    "Se incoporan compuertas que pueden aprender qué datos de una secuencia es importante conservar o desechar.\n",
    "\n",
    "* Input gate: compuerta de entrada, para actualizar el estado de la celda.\n",
    "* Forget gate: decide que información debe guardarse u olvidarse.\n",
    "* Output gate: decide cual debe ser el siguiente estado oculto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890da4d-c09e-43f9-a5c9-f662d7cf6fff",
   "metadata": {},
   "source": [
    "Lo **principal idea** de las **LSTM** son el **estado de la celda** y las **compuertas**. El estado de la celda es como la memoria de la red; ya que puede transportar información relevante a lo largo del procesamiento de la secuencia.\n",
    "\n",
    "A medida que el estado de la celda va pasando a través de las distintas celdas a lo largo del tiempo, la información se agrega o elimina al estado de la celda a través de compuertas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090d20a-0026-4212-910e-338fecc90cce",
   "metadata": {},
   "source": [
    "<img src=\"images/inside_lstm.png\" alt=\"drawing\" width=\"450\"/>\n",
    "<img src=\"images/elements_lstm.png\" alt=\"drawing\" width=\"370\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e99b5-517f-4f34-8408-973858805c22",
   "metadata": {},
   "source": [
    "**Forget gate:**\n",
    "\n",
    "Uso de la función sigmoidea: valores entre 0 y 1. Útil para actualizar u olvidar datos (cuando es 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29603101-d8d5-4864-a877-f5ed02b1a04e",
   "metadata": {},
   "source": [
    "**Input gate:**\n",
    "\n",
    "Para actualizar el estado de la celda. Primero se pasa el estado oculto anterior y la entrada actual a una función sigmoidea (elegir valores importantes y no importantes). También entran a una función tanh (valores entre -1 y 1) para regular los valores de la red (aplanar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec60e74-87e4-460f-8c18-e4594d64885f",
   "metadata": {},
   "source": [
    "**Cell state:**\n",
    "\n",
    "El estado de la celda se calcula:\n",
    "\n",
    "    1. Multiplicar el estado de la celda actual por el vector de *forget gate*\n",
    "    2. Se toma la salida de la compuerta de entrada y se hace una suma elemento a elemento con el paso anterior.\n",
    "    3. Eso da un nuevo estado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f9f7d-cfc7-4141-8b2c-6667dd400fe7",
   "metadata": {},
   "source": [
    "**Output gate:**\n",
    "\n",
    "La compuerta de salida decide cual debe ser el siguiente estado oculto. \n",
    "\n",
    "    1. Se pasa el estado oculto anterior y la entrada actual a una función sigmoidea. \n",
    "    2. Luego se pasa el estado de celda recién modificado a la función tanh. \n",
    "    3. Se multiplica la salida tanh con la salida sigmoidea para decidir qué información debe llevar el estado oculto. \n",
    "    4. La salida es el estado oculto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d629c49-7661-4049-a519-19d59d1d3140",
   "metadata": {},
   "source": [
    "## GRU - Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ff311-8edf-4cf6-afd8-21998b15b94b",
   "metadata": {},
   "source": [
    "Es una simplificación (y mas nueva) de las LSTM.\n",
    "\n",
    "Básicamente se deshace del **estado de celda** y utiliza el **estado oculto** para transferir la información.\n",
    "\n",
    "Tiene 2 compuertas:\n",
    "\n",
    "* **Reset gate**: como la forget gate de la LSTM.\n",
    "* **Update gate**: básicamente se usa para decidir cuanta información pasada se debe olvidar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0d87e-5c21-4105-a63d-63291acbdf5f",
   "metadata": {},
   "source": [
    "<img src=\"images/gru.png\" alt=\"drawing\" width=\"450\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe74555-177d-40b6-8670-fedcf3eefb7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aplicaciones de las RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8e9b3-575a-4dae-a5b4-74f7c5c1ba97",
   "metadata": {},
   "source": [
    "Primero hay que entender que clase de problema es:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa452b9-4309-4167-9065-c95a4bb5d6ef",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn_types.jpeg\" alt=\"drawing\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98436d2a-076a-4bbc-bdac-bacc438f6ac1",
   "metadata": {},
   "source": [
    "* **One to one**: Modelo sin procesamiento RNN\n",
    "\n",
    "* **One to many**: salida en secuencia. Por ej. prediccion de descripción de imagenes (image captioning)\n",
    "\n",
    "* **Many to one**: secuencia de entrada, unico elemento de salida. Por ej. sentiment analysis (text)\n",
    "    \n",
    "* **Many to many**: secuencia de entrada y secuencia de salida. Por ej. Traducción de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209df928-f475-4c10-bc74-ee69429e1a71",
   "metadata": {},
   "source": [
    "**Algunos ejemplos**\n",
    "\n",
    "1. Reconocimiento de voz\n",
    "2. Image captioning\n",
    "3. Traducción\n",
    "4. Sentiment analysis\n",
    "5. Etiquetado de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cc6a1-e185-4cef-bc63-b18a262bf9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
